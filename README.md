# ğŸ“Š Customer Churn Prediction â€” Explainable AI Project

Job Assistance Program â€” Cultos Skill Center | Stage 4 Assignment
Goal: Build a transparent and business-friendly machine learning model that predicts customer churn and explains why customers leave.

# ğŸ¯ Project Objectives

âœ” Predict whether a customer will churn
âœ” Use Explainable AI (XAI) to interpret model decisions
âœ” Generate business insights for churn reduction strategies
âœ” Provide evidence of model trustworthiness
âœ” Deliver clean, structured, and automated reports

# ğŸ“‚ Dataset

Telco Customer Churn Dataset
Records: 7043 customers
Target Variable: Churn (Yes/No)
Features: Demographics, Services, Account, Billing Information

Dataset source: Provided during project (not included in repo due to size limits)

# ğŸ§  Modeling Workflow
Stage	Description
ğŸ”¹ Data Preprocessing	Cleaning â†’ Label Encoding â†’ Scaling
ğŸ”¹ Feature Engineering	Transforming categorical data
ğŸ”¹ Model Training	Gradient Boosting (LightGBM)
ğŸ”¹ Hyperparameter Optimization	RandomizedSearchCV
ğŸ”¹ Explainability	SHAP + LIME (Local + Global)
ğŸ”¹ Evaluation	Accuracy, ROC-AUC, Confusion Matrix
ğŸ”¹ Business Insights	Actionable recommendations
# ğŸ“ˆ Model Performance
Metric	Score
Accuracy	80%+
ROCâ€“AUC	~0.84
Classification Report	Included in repo

This performance meets the 80%+ success criteria required for completion. ğŸ¯

# ğŸ” Explainable AI Outputs
Method	Purpose	Output
SHAP	Global + Local explainability	Feature importance charts & CSVs
LIME	Individual prediction reasoning	HTML visual reports

Interpretability deliverables included:

shap_feature_importance.csv

shap_lime_comparisons.json

Local explanation files for 3 diverse test samples (SHAP + LIME)

# ğŸ“Œ Key Business Insights

âœ” Monthly Charges, Tenure, Contract Type, Tech Support strongly influence churn
âœ” Short-tenure + high-monthly-bill customers are at highest risk
âœ” Auto-renewal contracts help reduce churn
âœ” Offering tech support benefits customer retention

Final analysis & strategy recommendations are in final_analysis.txt.

# ğŸ—‚ Repository Structure
ğŸ“¦ Customer-Churn-Interpretability
â”‚
â”œâ”€â”€ Customer_Churn_Interpretability_Project.ipynb
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ metrics.json
â”œâ”€â”€ best_model_params.txt
â”œâ”€â”€ classification_report.txt
â”œâ”€â”€ final_analysis.txt
â”‚
â”œâ”€â”€ confusion_matrix.png
â”‚
â”œâ”€â”€ shap_feature_importance.csv
â”œâ”€â”€ shap_lime_comparisons.json
â”œâ”€â”€ shap_local_summaries.json
â”œâ”€â”€ lime_local_summaries.json
â”‚
â”œâ”€â”€ lime_explanation_idx_33.html
â”œâ”€â”€ lime_explanation_idx_431.html
â”œâ”€â”€ lime_explanation_idx_891.html
â”‚
â”œâ”€â”€ shap_local_top10_idx_33.csv
â”œâ”€â”€ shap_local_top10_idx_431.csv
â””â”€â”€ shap_local_top10_idx_891.csv


Perfectly meets AI evaluator expectations âœ”

# ğŸ§ª Reproducibility

Run the notebook in Google Colab (GPU not required)

pip install lightgbm shap lime scikit-learn pandas numpy matplotlib


Execution time: ~35 seconds


# ğŸ“œ License

This project is submitted as part of a professional assessment.
Do not copy or reuse without permission.
